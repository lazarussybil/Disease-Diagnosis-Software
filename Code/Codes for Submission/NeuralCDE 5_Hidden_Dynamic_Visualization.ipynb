{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import random\n",
    "import sklearn\n",
    "import warnings\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from openTSNE import TSNE\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.cluster import AffinityPropagation, SpectralClustering\n",
    "\n",
    "from NeuralCDE_utils import *\n",
    "\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore::UserWarning\"\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "sklearn.set_config(print_changed_only=True)\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.use_deterministic_algorithms = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "data_type = 'Co_Po'\n",
    "parser.add_argument('--seed', type = int, default = SEED)\n",
    "\n",
    "parser.add_argument('--video_img_dir', type = str, default = f'Data\\\\Video_Images_{data_type}')\n",
    "parser.add_argument('--figure_save_dir', type = str, default = f'Figures\\\\NeuralCDE_{data_type}')\n",
    "parser.add_argument('--backbone_path', type = str, default = f'Model\\Feature_Extractor_{data_type}\\model.pkl')\n",
    "parser.add_argument('--model_path', type = str, default = f'Model\\\\NeuralCDE_Naive_{data_type}\\model.pkl')\n",
    "parser.add_argument('--pred_figure_save_dir', type = str, default = f'Prediction_Visualization')\n",
    "parser.add_argument('--pred_save_path', type = str, default = f'Prediction_Visualization\\\\NeuralCDE_Naive_{data_type}.pkl')\n",
    "parser.add_argument('--tsne_save_path', type = str, default = f'Prediction_Visualization\\\\TSNE_{data_type}.pkl')\n",
    "parser.add_argument('--num_clusters', type = int, default = 4)\n",
    "parser.add_argument('--adjoint', type = bool, default = True)\n",
    "parser.add_argument('--img_input_size', type = int, default = 128)\n",
    "parser.add_argument('--img_output_size', type = int, default = 32)\n",
    "parser.add_argument('--hidden_size', type = int, default = 16)\n",
    "parser.add_argument('--output_size', type = int, default = 2)\n",
    "\n",
    "parser.add_argument('--batch_size', type = int, default = 1)\n",
    "parser.add_argument('--workers', type = int, default = 0)\n",
    "parser.add_argument('--device', default = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading Training Set')\n",
    "datasets = KvasirVideoDataset(os.path.join(args.video_img_dir, 'Train'), args.img_input_size, strong_transform=False, visualize=True)\n",
    "data_loader = DataLoader(datasets, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralCDEVisual(args).to(args.device)\n",
    "model.load_state_dict(torch.load(args.model_path).state_dict())\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_pred_model = HiddenStatePred(args).to(args.device)\n",
    "model.load_state_dict(torch.load(args.model_path).state_dict())\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zs.shape == (batch_size, n_frame, hidden_size) \\\n",
    "pred_label.shape == (batch_size, 1) \\\n",
    "true_y.shape == (batch_size, 1) \\\n",
    "step_y.shape == (batch_size, n_frame, 1) \\\n",
    "all_zs.shape == (batch_size * n_frame, hidden_size) \\\n",
    "all_ys.shape == (batch_size * n_frame, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(args.pred_figure_save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(args.pred_save_path):\n",
    "    zs = []\n",
    "    pred_label = []\n",
    "    true_y = []\n",
    "    step_p = []\n",
    "    names = []\n",
    "    for (b_x, b_y, b_name) in tqdm(data_loader):\n",
    "        true_y.append(int(b_y))\n",
    "        names.append(b_name)\n",
    "        z_T, label = model(b_x.to(args.device))\n",
    "        zs.append(z_T.detach().cpu().numpy())\n",
    "        pred_label.append(int(label))\n",
    "        step_p.append(z_pred_model(z_T, p=True).detach().cpu().numpy())\n",
    "    all_zs = np.concatenate(zs)\n",
    "    all_ys = []\n",
    "    for i, z in enumerate(zs):\n",
    "        all_ys += [true_y[i]] * z.shape[0]\n",
    "    all_ys = np.array(all_ys)\n",
    "    with open(args.pred_save_path, 'wb') as f:\n",
    "        pickle.dump((zs, pred_label, true_y, step_p, all_zs, all_ys, names), f)\n",
    "\n",
    "else:\n",
    "    with open(args.pred_save_path, 'rb') as f:\n",
    "        print('Loading data from', args.pred_save_path)\n",
    "        zs, pred_label, true_y, step_p, all_zs, all_ys, names = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_2d = TSNE(n_components=2, perplexity=30, metric=\"euclidean\", n_jobs=8, random_state=args.seed, verbose=False)\n",
    "embedding_train = tsne_2d.fit(all_zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10), dpi=80)\n",
    "sns.scatterplot(x = embedding_train[:, 0], y = embedding_train[:, 1], hue=all_ys)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Hidden State Space Distribution w.r.t Ground Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10), dpi=80)\n",
    "sns.scatterplot(x = embedding_train[:, 0], y = embedding_train[:, 1], hue=np.concatenate(step_p))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Hidden State Space Distribution w.r.t Predicted Probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette(\"flare\", as_cmap=True)\n",
    "for ith, z_T in enumerate(tqdm(zs)):\n",
    "    embedding_test = np.array(embedding_train.transform(z_T))\n",
    "    z_T_with_t = np.array([z_T[i].tolist() + [i / 5] for i in range(embedding_test.shape[0])])\n",
    "\n",
    "    plt.figure(figsize=(20, 20), dpi=300)\n",
    "    plt.subplot(3, 3, 1)\n",
    "    sns.scatterplot(x=embedding_test[:, 0], y=embedding_test[:, 1], hue=np.arange(z_T.shape[0]), s=30, alpha=0.8, palette=palette)\n",
    "    sns.lineplot(x=embedding_test[:, 0], y=embedding_test[:, 1], sort=False, linewidth=0.3, markers=True, palette=palette)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title('Hidden State Dynamics with Time')\n",
    "\n",
    "    plt.subplot(3, 3, 2)\n",
    "    sns.scatterplot(x=embedding_test[:, 0], y=embedding_test[:, 1], hue=z_pred_model(torch.from_numpy(z_T).to(args.device), p=True).detach().cpu().numpy(), s=30, alpha=0.8, palette=palette)\n",
    "    sns.lineplot(x=embedding_test[:, 0], y=embedding_test[:, 1], sort=False, linewidth=0.3, markers=True, palette=palette)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title('Predicted Probability Dynamics')\n",
    "\n",
    "    plt.subplot(3, 3, 3)\n",
    "    sns.scatterplot(x=embedding_test[:, 0], y=embedding_test[:, 1], hue=z_pred_model(torch.from_numpy(z_T).to(args.device)).detach().cpu().numpy(), s=30, alpha=0.8, legend = False)\n",
    "    sns.lineplot(x=embedding_test[:, 0], y=embedding_test[:, 1], sort=False, linewidth=0.3, markers=True, palette=palette)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title('Predicted Label Dynamics')\n",
    "    plt.subplot(3, 3, 3)\n",
    "    sns.scatterplot(x=embedding_test[:, 0], y=embedding_test[:, 1], hue=z_pred_model(torch.from_numpy(z_T).to(args.device)).detach().cpu().numpy(), s=30, alpha=0.8)\n",
    "    sns.lineplot(x=embedding_test[:, 0], y=embedding_test[:, 1], sort=False, linewidth=0.3, markers=True, palette=palette)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title('Predicted Label Dynamics')\n",
    "\n",
    "    for ith_rate, damping_rate in enumerate([0.55, 0.8, 0.95]):\n",
    "        plt.subplot(3, 3, ith_rate + 4)\n",
    "        model = AffinityPropagation(damping=damping_rate, random_state=args.seed)\n",
    "        model.fit(z_T_with_t)\n",
    "        yhat = model.predict(z_T_with_t)\n",
    "        clusters = np.unique(yhat)\n",
    "\n",
    "        for cluster in clusters:\n",
    "            row_ix = np.where(yhat == cluster)\n",
    "            sns.scatterplot(x=embedding_test[row_ix, 0].squeeze(), y=embedding_test[row_ix, 1].squeeze(), s=30, alpha=0.8)\n",
    "        sns.lineplot(x=embedding_test[:, 0], y=embedding_test[:, 1], sort=False, linewidth=0.3, markers=True, palette=palette)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(f'Affinity Propagation Clustering \\n with damping = {damping_rate}')\n",
    "\n",
    "    for ith_clusters, num_clusters in enumerate([4, 6, 8]):\n",
    "        plt.subplot(3, 3, ith_clusters + 7)\n",
    "        model = SpectralClustering(n_clusters=num_clusters, random_state=args.seed)\n",
    "        yhat = model.fit_predict(z_T_with_t)\n",
    "        clusters = np.unique(yhat)\n",
    "\n",
    "        for cluster in clusters:\n",
    "            row_ix = np.where(yhat == cluster)\n",
    "            sns.scatterplot(x=embedding_test[row_ix, 0].squeeze(), y=embedding_test[row_ix, 1].squeeze(), s=30, alpha=0.8)\n",
    "        sns.lineplot(x=embedding_test[:, 0], y=embedding_test[:, 1], sort=False, linewidth=0.3, markers=True, palette=palette)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(f'Spectral Clustering \\n with n_clusters = {num_clusters}')\n",
    "\n",
    "    plt.suptitle(names[ith][0], fontsize=50, y=0.95)\n",
    "    plt.savefig(os.path.join(args.pred_figure_save_dir, f'{names[ith][0]}.eps'), format='eps')\n",
    "    plt.savefig(os.path.join(args.pred_figure_save_dir, f'{names[ith][0]}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    clip_time = defaultdict(list)\n",
    "    for ith, z_T in enumerate(tqdm(zs)):\n",
    "        clip_time['img'].append(names[ith][0])\n",
    "\n",
    "        model = SpectralClustering(n_clusters=args.num_clusters + 2 * i, random_state=args.seed)\n",
    "        yhat = model.fit_predict(np.array([z_T[i].tolist() + [i / 5] for i in range(z_T.shape[0])]))\n",
    "        clusters = np.unique(yhat)\n",
    "        times = []\n",
    "        for ith_cluster, cluster in enumerate(clusters):\n",
    "            times.append(np.where(yhat == cluster)[0][0] // 5)\n",
    "\n",
    "        for ith_time, t in enumerate(sorted(times)):\n",
    "            clip_time['time' + str(ith_time)].append(t)\n",
    "\n",
    "    pd.DataFrame(dict(clip_time)).to_csv(os.path.join(args.pred_figure_save_dir, f'Clipping Time with k = {args.num_clusters + 2 * i}.csv'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0747f93ff6db21b2db2bf35ad4858dd0825b9c21797c41b4cc32097944ab3f10"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
